# /usr/bin/env python
# -*- mode: python -*-
# =============================================================================
#  @@-COPYRIGHT-START-@@
#
#  Copyright (c) 2024, Qualcomm Innovation Center, Inc. All rights reserved.
#
#  Redistribution and use in source and binary forms, with or without
#  modification, are permitted provided that the following conditions are met:
#
#  1. Redistributions of source code must retain the above copyright notice,
#     this list of conditions and the following disclaimer.
#
#  2. Redistributions in binary form must reproduce the above copyright notice,
#     this list of conditions and the following disclaimer in the documentation
#     and/or other materials provided with the distribution.
#
#  3. Neither the name of the copyright holder nor the names of its contributors
#     may be used to endorse or promote products derived from this software
#     without specific prior written permission.
#
#  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
#  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
#  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
#  ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
#  LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
#  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
#  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
#  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
#  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
#  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
#  POSSIBILITY OF SUCH DAMAGE.
#
#  SPDX-License-Identifier: BSD-3-Clause
#
#  @@-COPYRIGHT-END-@@
# =============================================================================
"""Utilities to achieve mixed precision"""

from dataclasses import dataclass
from enum import Enum
from typing import Dict, Type, List, Literal, Optional, Union

import torch

from aimet_common.defs import QuantizationDataType
from aimet_common.utils import AimetLogger
from aimet_torch.v2.nn import BaseQuantizationMixin
from aimet_torch.v2.quantization.float.quantizer import FloatQuantizeDequantize
from aimet_torch.v2.cg_utils import ModuleProduct

logger = AimetLogger.get_area_logger(AimetLogger.LogAreas.Quant)

SupportedDType = Literal['int16', 'int8', 'int4', 'fp16']

@dataclass
class Precision:
    """ Internal data structure to represent quantization data type and bitwidth """
    data_type: QuantizationDataType
    bitwidth: int

    def __lt__(self, other):
        if self == other:
            return False
        if self.bitwidth != other.bitwidth:
            return self.bitwidth < other.bitwidth
        return self.data_type == QuantizationDataType.int and other.data_type != QuantizationDataType.int

    def __repr__(self):
        return f'{self.data_type.name}{self.bitwidth}'


TranslateUserDtypes = {
    'int16': Precision(QuantizationDataType.int, 16),
    'int8': Precision(QuantizationDataType.int, 8),
    'int4': Precision(QuantizationDataType.int, 4),
    'fp16': Precision(QuantizationDataType.float, 16),
}


@dataclass
class MpRequest:
    """ Internal data structure to save the request to act upon"""
    id: int = None  # original request ID
    input_candidates: List[Optional[Precision]] = None
    output_candidates: List[Optional[Precision]] = None
    param_candidate: Dict[str, Optional[Precision]] = None

    def __eq__(self, other):
        return self.id == other.id and self.is_same_precision(other)

    def fuse(self, other):
        """ Function to fuse two MpRequest objects, defaulting to self, and filling in None fields from other."""
        if not self:
            return other
        if not other:
            return self
        if not isinstance(self, MpRequest):
            raise NotImplementedError("Cannot add MpRequest object to non-MpRequest object.")

        fused_request = MpRequest()

        # We want to always defer to the newer request when there is a conflict
        newer_request = self if self.id > other.id else other
        older_request = other if newer_request is self else self

        # TODO: how do we handle id? defaulting to latest id
        fused_request.id = newer_request.id

        def fuse_lists(old_list, new_list):
            if old_list is None:
                return new_list
            if new_list is None:
                return old_list
            if len(new_list) != len(old_list):
                raise RuntimeError("Cannot combine two MpRequest objects with different number of candidates.")
            return [new if new else old for new, old in zip(new_list, old_list)]

        fused_request.input_candidates = fuse_lists(older_request.input_candidates, newer_request.input_candidates)
        fused_request.output_candidates = fuse_lists(older_request.output_candidates, newer_request.output_candidates)

        if older_request.param_candidate is None:
            fused_request.param_candidate = newer_request.param_candidate
        if newer_request.param_candidate is None:
            fused_request.param_candidate = older_request.param_candidate
        else:
            # Take param_candidate from RHS if possible, else default to LHS
            fused_request.param_candidate = older_request.param_candidate.update(newer_request.param_candidate)

        return fused_request

    def is_same_precision(self, other):
        """ Compare the precision between self and other"""
        return ((self.input_candidates == other.input_candidates) and
                (self.output_candidates == other.output_candidates) and
                (self.param_candidate == other.param_candidate))

class RequestType(Enum):
    """Enum to represent the type of request made by the user"""
    set_precision_by_module = 1
    set_precision_by_module_type = 2
    set_model_input_precision = 3
    set_model_output_precision = 4

@dataclass
class UserRequest:
    """ Data structure to store user requests"""
    request_type: RequestType
    module: Union[torch.nn.Module, Type, ModuleProduct, None] = None
    activation: Union[List[SupportedDType], SupportedDType, None] = None
    param: Optional[Dict[str, SupportedDType]] = None

def _is_qtzr_higher_precision_than_candidate(qtzr: BaseQuantizationMixin, candidate: Precision) -> bool:
    """ Helper function to determine if qtzr is higher precision than candidate """
    qtzr_dtype = QuantizationDataType.float if isinstance(qtzr, FloatQuantizeDequantize) else QuantizationDataType.int
    generated_candidate = Precision(qtzr_dtype, qtzr.bitwidth)
    return generated_candidate > candidate

def broadcast_tuples(inp_a, inp_b):
    """ Broadcast inp_a to match inp_b shape if possible, or raise RuntimeError """
    if not isinstance(inp_a, (tuple, list)) and not isinstance(inp_b, (tuple, list)):
        return inp_a

    if not isinstance(inp_a, (tuple, list)) and isinstance(inp_b, (tuple, list)):
        return tuple(broadcast_tuples(inp_a, inp_b_elem) for inp_b_elem in inp_b)

    if isinstance(inp_a, (tuple, list)) and isinstance(inp_b, (tuple, list)):
        if len(inp_a) == len(inp_b):
            return tuple(broadcast_tuples(inp_a_elem, inp_b_elem) for inp_a_elem, inp_b_elem in \
                         zip(inp_a, inp_b))

    raise RuntimeError("Incompatible tuple sizes.")
