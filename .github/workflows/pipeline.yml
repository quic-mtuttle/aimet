name: CI Pipeline

on:
  workflow_call:

jobs:
  docker-tag:
    name: Check if 'latest' tag could be used (no build docker images)
    runs-on: ubuntu-latest
    outputs:
      tag: ${{ steps.tag.outputs.tag }}
    steps:
      - uses: actions/checkout@v4
      - uses: ./.github/actions/docker-tag
        id: tag
        with:
          dockerfile: Jenkins/fast-release/Dockerfile.ci

  variants:
    name: Define supported AIMET variants
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.final.outputs.value }}
    steps:
      - uses: actions/checkout@v4
      - name: Get changed files
        id: diff
        uses: ./.github/actions/changed-files
      - name: Select AIMET variants that needs testing
        id: select
        env:
          ALL_CHANGED_FILES: ${{ steps.diff.outputs.changed_files }}
          AIMET_TORCH_SRC_CODE: "TrainingExtensions/torch/*"
          AIMET_ONNX_SRC_CODE:  "TrainingExtensions/onnx/*"
          AIMET_TF_SRC_CODE:    "TrainingExtensions/tensorflow/*"
        shell: bash
        run: |
          set -x

          TORCH_TEST_REQUIRED='false'
          ONNX_TEST_REQUIRED='false'
          TF_TEST_REQUIRED='false'

          for file in ${ALL_CHANGED_FILES}; do
            if [[ $file == $AIMET_TORCH_SRC_CODE ]]; then
              TORCH_TEST_REQUIRED='true'
            elif [[ $file == $AIMET_ONNX_SRC_CODE ]]; then
              ONNX_TEST_REQUIRED='true'
            elif [[ $file == $AIMET_TF_SRC_CODE ]]; then
              TF_TEST_REQUIRED='true'
            else
              TORCH_TEST_REQUIRED='true'
              ONNX_TEST_REQUIRED='true'
              TF_TEST_REQUIRED='true'
              break
            fi
          done

          echo "test_torch=$TORCH_TEST_REQUIRED" >> $GITHUB_OUTPUT
          echo "test_onnx=$ONNX_TEST_REQUIRED"   >> $GITHUB_OUTPUT
          echo "test_tf=$TF_TEST_REQUIRED"       >> $GITHUB_OUTPUT
      - name: Torch variants
        # For the default branch, we still test all variants every time (yet)
        if: steps.select.outputs.test_torch == 'true' || github.ref_name == github.event.repository.default_branch
        run: |
          VALUE=$(echo "${VALUE:-"{}"}" | jq -c '.include += [
              {
                 "id":              "torch-cpu",
                 "runs-on":         "ubuntu-latest",
                 "VER_PYTHON":      "3.10",
                 "VER_TENSORFLOW":  "",
                 "VER_TORCH":       "2.1.2",
                 "VER_ONNXRUNTIME": "",
                 "VER_CUDA":        "",
                 "ENABLE_TESTS":    "ON",
                 "BUILD_TARGETS":   "all"
              },
              {
                 "id":              "torch-gpu",
                 "runs-on":         "k8s-gpu",
                 "VER_PYTHON":      "3.10",
                 "VER_TENSORFLOW":  "",
                 "VER_TORCH":       "2.1.2",
                 "VER_ONNXRUNTIME": "",
                 "VER_CUDA":        "12.1.1",
                 "ENABLE_TESTS":    "ON",
                 "BUILD_TARGETS":   "all"
              }
            ]')
          echo "VALUE=$VALUE" >> $GITHUB_ENV
      - name: Tensorflow variants
        # For the default branch, we still test all variants every time (yet)
        if: steps.select.outputs.test_tf == 'true' || github.ref_name == github.event.repository.default_branch
        run: |
          VALUE=$(echo "${VALUE:-"{}"}" | jq -c '.include += [
              {
                 "id":              "tf-cpu",
                 "runs-on":         "ubuntu-latest",
                 "VER_PYTHON":      "3.10",
                 "VER_TENSORFLOW":  "2.10.1",
                 "VER_TORCH":       "",
                 "VER_ONNXRUNTIME": "",
                 "VER_CUDA":        "",
                 "ENABLE_TESTS":    "ON",
                 "BUILD_TARGETS":   "all"
              },
              {
                 "id":              "tf-gpu",
                 "runs-on":         "k8s-gpu",
                 "VER_PYTHON":      "3.10",
                 "VER_TENSORFLOW":  "2.10.1",
                 "VER_TORCH":       "",
                 "VER_ONNXRUNTIME": "",
                 "VER_CUDA":        "11.8.0",
                 "ENABLE_TESTS":    "ON",
                 "BUILD_TARGETS":   "all"
              }
            ]')
          echo "VALUE=$VALUE" >> $GITHUB_ENV
      - name: ONNX variants
        # For the default branch, we still test all variants every time (yet)
        if: steps.select.outputs.test_onnx == 'true' || github.ref_name == github.event.repository.default_branch
        run: |
          VALUE=$(echo "${VALUE:-"{}"}" | jq -c '.include += [
              {
                 "id":              "onnx-cpu",
                 "runs-on":         "ubuntu-latest",
                 "VER_PYTHON":      "3.10",
                 "VER_TENSORFLOW":  "",
                 "VER_TORCH":       "",
                 "VER_ONNXRUNTIME": "1.18.1",
                 "ENABLE_TESTS":    "ON",
                 "BUILD_TARGETS":   "all"
              },
              {
                 "id":              "onnx-gpu",
                 "runs-on":         "k8s-gpu",
                 "VER_PYTHON":      "3.10",
                 "VER_TENSORFLOW":  "",
                 "VER_TORCH":       "",
                 "VER_ONNXRUNTIME": "1.18.1",
                 "VER_CUDA":        "11.8.0",
                 "ENABLE_TESTS":    "ON",
                 "BUILD_TARGETS":   "all"
              }
            ]')
          echo "VALUE=$VALUE" >> $GITHUB_ENV

      - name: Doc variants
        run: |
          VALUE=$(echo "${VALUE:-"{}"}" | jq -c '.include += [
              {
                 "id":              "tf-torch-cpu",
                 "runs-on":         "ubuntu-latest",
                 "VER_PYTHON":      "3.10",
                 "VER_TENSORFLOW":  "2.12.*",
                 "VER_TORCH":       "2.1.2",
                 "VER_ONNXRUNTIME": "1.18.1",
                 "VER_CUDA":        "",
                 "ENABLE_TESTS":    "OFF",
                 "BUILD_TARGETS":   "all;doc"
              }
            ]')
          echo "VALUE=$VALUE" >> $GITHUB_ENV

      - name: (Last step) Generate few extra properties for each variant
        id: final
        run: |
          echo "value=$VALUE" >> $GITHUB_OUTPUT

  docker-build-image:
    name: Docker image ${{ matrix.id }}
    runs-on: ubuntu-latest
    needs: [docker-tag, variants]
    strategy:
      matrix: ${{ fromJSON(needs.variants.outputs.matrix) }}
    steps:
      - uses: actions/checkout@v4
      - uses: ./.github/actions/docker-build-image
        with:
          dockerfile: Jenkins/fast-release/Dockerfile.ci
          docker-login: ${{ secrets.DOCKER_LOGIN }}
          docker-password: ${{ secrets.DOCKER_CREDENTIALS }}
          docker-registry: ${{ vars.DOCKER_REGISTRY }}
          image-name: "${{ vars.DOCKER_IMAGE }}-${{ matrix.id }}"
          image-tag: ${{ needs.docker-tag.outputs.tag }}
          build-args: |
            VER_PYTHON=${{ matrix.VER_PYTHON }}
            VER_CUDA=${{ matrix.VER_CUDA }}
            VER_TORCH=${{ matrix.VER_TORCH }}
            VER_TENSORFLOW=${{ matrix.VER_TENSORFLOW }}
            VER_ONNXRUNTIME=${{ matrix.VER_ONNXRUNTIME }}
            AIMET_VARIANT=${{ matrix.id }}

  build-wheel:
    name: Build AIMET wheels
    runs-on: ${{ matrix.runs-on }}
    needs: [docker-tag, variants, docker-build-image]
    strategy:
      matrix: ${{ fromJSON(needs.variants.outputs.matrix) }}
    defaults:
      run:
        shell: bash
    container:
      image: "${{ vars.DOCKER_REGISTRY }}/${{ vars.DOCKER_IMAGE }}-${{ matrix.id }}:${{ needs.docker-tag.outputs.tag }}"
      credentials:
        username: ${{ secrets.DOCKER_LOGIN }}
        password: ${{ secrets.DOCKER_CREDENTIALS }}
    steps:
      - uses: actions/checkout@v4
      - name: "Generate CMAKE_ARGS"
        run: |
          set -x
          CMAKE_ARGS=""
          CMAKE_ARGS="-DENABLE_CUDA=$([ "${{ matrix.VER_CUDA }}" = "" ] && echo OFF || echo ON) $CMAKE_ARGS"
          CMAKE_ARGS="-DENABLE_TORCH=$([ "${{ matrix.VER_TORCH }}" = "" ] && echo OFF || echo ON) $CMAKE_ARGS"
          CMAKE_ARGS="-DENABLE_ONNX=$([ "${{ matrix.VER_ONNXRUNTIME }}" = "" ] && echo OFF || echo ON) $CMAKE_ARGS"
          CMAKE_ARGS="-DENABLE_TENSORFLOW=$([ "${{ matrix.VER_TENSORFLOW }}" = "" ] && echo OFF || echo ON) $CMAKE_ARGS"
          CMAKE_ARGS="-DENABLE_TESTS=${{ matrix.ENABLE_TESTS }} $CMAKE_ARGS"
          echo "AIMET_CMAKE_ARGS=$CMAKE_ARGS" >> $GITHUB_ENV

          BUILD_TARGETS="${{ matrix.BUILD_TARGETS }}"
          echo "AIMET_BUILD_TARGETS=$BUILD_TARGETS" >> $GITHUB_ENV
      - name: "Exclude Torch libraries from dependencies for manylinux"
        if: matrix.VER_TORCH || matrix.VER_ONNXRUNTIME
        run: |
          . /etc/profile.d/conda.sh
          TORCH_DIR=$(python3 -c 'import torch; print(f"{torch.utils.cmake_prefix_path}/../../lib")')
          MANYLINUX_EXCLUDE_LIBS="$MANYLINUX_EXCLUDE_LIBS $(find $TORCH_DIR -name '*.so*' | xargs -r patchelf --print-soname | xargs -r printf -- '--exclude %s ')"
          set -x
          echo "MANYLINUX_EXCLUDE_LIBS=$MANYLINUX_EXCLUDE_LIBS" >> $GITHUB_ENV
      - name: "Exclude CUDA libraries from dependencies for manylinux"
        if: matrix.VER_CUDA
        run: |
          . /etc/profile.d/conda.sh
          CUBLAS_DIR=$(python3 -c 'import sysconfig ; from pathlib import Path; print(Path(sysconfig.get_config_var("prefix"), "lib"))')
          MANYLINUX_EXCLUDE_LIBS="$MANYLINUX_EXCLUDE_LIBS $(find $CUBLAS_DIR -name '*blas.so*' | xargs -r patchelf --print-soname | xargs -r printf -- '--exclude %s ')"
          set -x
          echo "MANYLINUX_EXCLUDE_LIBS=$MANYLINUX_EXCLUDE_LIBS" >> $GITHUB_ENV
      - name: "Exclude Tensorflow libraries from dependencies for manylinux"
        if: matrix.VER_TENSORFLOW
        run: |
          . /etc/profile.d/conda.sh
          TF_DIR=$(python3 -c 'import tensorflow as tf; print(tf.sysconfig.get_lib())')
          CUBLAS_DIR=$(python3 -c 'import tensorflow as tf; print(f"{tf.sysconfig.get_lib()}/../../../../lib")')
          MANYLINUX_EXCLUDE_LIBS="$MANYLINUX_EXCLUDE_LIBS $(find $TF_DIR -name '*.so*' | xargs -r patchelf --print-soname | xargs -r printf --  '--exclude %s ')"
          MANYLINUX_EXCLUDE_LIBS="$MANYLINUX_EXCLUDE_LIBS $(find $CUBLAS_DIR -name '*blas.so*' | xargs -r patchelf --print-soname | xargs -r printf -- '--exclude %s ')"
          set -x
          echo "MANYLINUX_EXCLUDE_LIBS=$MANYLINUX_EXCLUDE_LIBS" >> $GITHUB_ENV
      - name: "Build AIMET wheel package"
        run: |
          set -x
          rm -rf build dist
          . /etc/profile.d/conda.sh
          export CMAKE_ARGS="$AIMET_CMAKE_ARGS"
          export SKBUILD_BUILD_TARGETS="$AIMET_BUILD_TARGETS"

          if [ "${{ matrix.id }}" == "tf-torch-cpu" ] ; then
            # Force-install tensorflow 2.10.1 since aimet isn't compatible with > 2.10
            # FIXME: Remove this line
            python3 -m pip install tensorflow-cpu==2.10.1 --no-deps
            # Required to work around tensorflow-protobuf version mismatch
            export PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
          fi

          python3 -m build --wheel --no-isolation .
          auditwheel repair --plat manylinux_2_34_x86_64 $MANYLINUX_EXCLUDE_LIBS dist/aimet*.whl

          if [ "${{ matrix.id }}" == "tf-torch-cpu" ] ; then
            # Unzip aimet*.whl in current directory to upload Docs
            python3 -m pip install -t wheelhouse --no-deps wheelhouse/aimet*.whl
          fi
      - name: Upload AIMET wheel file
        uses: actions/upload-artifact@v3
        with:
          name: "${{ matrix.id }}"
          path: |
            wheelhouse/aimet*.whl
            build/bin/MoDlCompressionTest
            build/bin/MoDlEqualizationTest
            build/bin/MoDlQuantizationTest
          if-no-files-found: error
          retention-days: 1d
      - name: Upload AIMET documentation
        if: matrix.id == 'tf-torch-cpu'
        uses: actions/upload-artifact@v3
        with:
          name: Docs
          path: wheelhouse/Docs/
          if-no-files-found: error
          retention-days: 1d

  test:
    name: Run AIMET unit tests
    # if: matrix.ENABLE_TESTS == 'ON' NOTE: Unfortunately, GitHub doesn't support accessing ${{ matrix }}
    #                                       in a job-level if condition. As a petty workaround, we insert
    #                                       this condition in every step in this job.
    #                                       (See also https://github.com/actions/runner/issues/1985)
    runs-on: ${{ matrix.runs-on }}
    needs: [variants, build-wheel]
    strategy:
      fail-fast: false
      matrix: ${{ fromJSON(needs.variants.outputs.matrix) }}
    env:
      pytest_github_report: true
      pytest_use_zeros: true
    container:
      image: "ubuntu:22.04"
    steps:
      - if: matrix.ENABLE_TESTS == 'ON'
        run: |
          apt update -qq
          apt install --no-install-recommends -y git curl g++ ca-certificates
          curl -sSL 'https://pki.qualcomm.com/{qc_root_g2_cert.crt,ssl_v3_cert.crt,ssl_v4_cert.crt}' > qualcomm.crt
          update-ca-certificates
          rm -rf download
      - if: matrix.ENABLE_TESTS == 'ON'
        uses: actions/checkout@v4
      - if: matrix.ENABLE_TESTS == 'ON'
        uses: actions/download-artifact@v3
        with:
          name: "${{ matrix.id }}"
          path: "downloads"
      - name: Try to load python virtual environment from the cache
        if: matrix.ENABLE_TESTS == 'ON'
        uses: actions/cache@v4
        id: cache
        with:
          path: ./.conda
          key: ${{ matrix.id }}-${{ hashFiles('pyproject.toml', 'packaging/dependencies/**/*.txt', 'packaging/dependencies/plugins/**/*.py') }}
      - name: Create python virtual environment
        if: ${{ matrix.id  != 'tf-torch-cpu' && steps.cache.outputs.cache-hit != 'true' }}
        run: |
          export PIP_EXTRA_INDEX_URL="https://download.pytorch.org/whl/$(echo "${{ matrix.VER_CUDA }}" | awk -F'.' '{print ($1!="")? "cu"$1$2 : "cpu"}')"

          curl -o ./conda.sh -L 'https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-Linux-x86_64.sh'
          bash ./conda.sh -u -b -p ./.conda
          sudo apt update -qq && sudo apt install -y g++ # deepspeed compiles cuda kernels
          ./.conda/bin/conda create --name "${{ matrix.id }}" python="${{ matrix.VER_PYTHON }}" $([ "${{ matrix.VER_CUDA }}" != "" ] && echo "cuda-runtime cuda-libraries-dev cuda-compiler --channel nvidia/label/cuda-${{ matrix.VER_CUDA }}")
          ./.conda/bin/conda run --live-stream --name "${{ matrix.id }}" python3 -m pip install "$(find downloads -name '*.whl')[test, v1-deps]"
      - name: Run pylint
        if: matrix.ENABLE_TESTS == 'ON'
        run: |
          CONDA_PYTHONPATH="./.conda/envs/${{ matrix.id }}/lib/python${{ matrix.VER_PYTHON }}/site-packages"
          AIMET_PACKAGES=$(find $CONDA_PYTHONPATH -regex ".*/aimet_\(common\|torch\|tensorflow\|onnx\)" | tr "\n" " ")

          ./.conda/bin/conda run --live-stream --name "${{ matrix.id }}" \
              python3 -m pylint --rcfile=.pylintrc $AIMET_PACKAGES
      - name: Run unit tests
        if: matrix.ENABLE_TESTS == 'ON'
        env:
          CTEST_TARGETS: |
            downloads/build/bin/MoDlCompressionTest
            downloads/build/bin/MoDlEqualizationTest
            downloads/build/bin/MoDlQuantizationTest
        run: |
          set -x

          for target in $CTEST_TARGETS; do
              chmod +x $target
              # NOTE: Set LD_LIBRARY_PATH for dynamic linking with libpython3.so
              #       since ubuntu:22.04 docker image doesn't have built-in libpython3.so
              LD_LIBRARY_PATH=".conda/envs/${{ matrix.id }}/lib" \
                  ./.conda/bin/conda run --live-stream --name "${{ matrix.id }}" $target
          done

          PYTEST_TARGETS="./ModelOptimizations/DlQuantization/test ./ModelOptimizations/DlEqualization/test"

          if [ "${{ matrix.VER_TENSORFLOW }}" != "" ] ; then
              PYTEST_TARGETS="$PYTEST_TARGETS ./TrainingExtensions/tensorflow/test"
          elif [ "${{ matrix.VER_ONNXRUNTIME }}" != "" ] ; then
              PYTEST_TARGETS="$PYTEST_TARGETS ./TrainingExtensions/onnx/test"
          elif [ "${{ matrix.VER_TORCH }}" != "" ] ; then
              PYTEST_TARGETS="$PYTEST_TARGETS ./TrainingExtensions/torch/test"
          fi
          PYTEST_ARGS="not blah"
          if [ "${{ matrix.VER_CUDA }}" = "" ] ; then
              PYTEST_ARGS="not cuda"
          fi
          ./.conda/bin/conda run --live-stream --name "${{ matrix.id }}" python3 -m pytest -m "$PYTEST_ARGS" $PYTEST_TARGETS

  docker-push-latest:
    needs: [docker-tag, variants, test]
    runs-on: ubuntu-latest
    strategy:
      matrix: ${{ fromJSON(needs.variants.outputs.matrix) }}
    steps:
      - run: sudo sh -c "cp /tmp/certs/* /usr/local/share/ca-certificates/ && update-ca-certificates"
      - uses: docker/setup-buildx-action@v3
        with:
          driver: docker
      - uses: docker/login-action@v3
        with:
          registry: ${{ vars.DOCKER_REGISTRY }}
          username: ${{ secrets.DOCKER_LOGIN }}
          password: ${{ secrets.DOCKER_CREDENTIALS }}
      - name: Create the 'latest' docker image tag
        if: ${{ github.ref_name == github.event.repository.default_branch && needs.docker-tag.outputs.tag != 'latest' }}
        run: docker buildx imagetools create ${{ vars.DOCKER_REGISTRY }}/${{ vars.DOCKER_IMAGE }}-${{ matrix.id }}:${{ needs.docker-tag.outputs.tag }} --tag ${{ vars.DOCKER_REGISTRY }}/${{ vars.DOCKER_IMAGE }}-${{ matrix.id }}:latest

  cleanup:
    needs: [docker-tag, variants, docker-push-latest]
    runs-on: ubuntu-latest
    strategy:
      matrix: ${{ fromJSON(needs.variants.outputs.matrix) }}
    steps:
      - name: Delete temp docker image
        if: needs.docker-tag.outputs.tag != 'latest'
        run: curl -k -H "Authorization:Bearer ${{ secrets.DOCKER_CREDENTIALS }}" -X DELETE "https://${{ vars.DOCKER_REGISTRY }}/v2/${{ vars.DOCKER_IMAGE }}-${{ matrix.id }}/manifests/${{ needs.docker-tag.outputs.tag }}" || true
